---
layout: post
title: 'k3s的pod暴露服务在宿主机上'
date: 2023-03-04
categories: k3s
author: Jason
tags: k3s hostport iptables
---

# k3s POD暴露服务手段
## HostPort

------

平时想到通过端口来暴露服务，首先想到的一般都是nodeport这种方式，这次在排查一个端口占用的问题时，发现使用的是hostport方式来暴露port的服务。下面就来聊聊处理的过程

## 处理过程 

使用kubectl apply -f nginx_deployment.yaml来部署一个nginx的deployment，发现pod没有正常提供服务，报错如下：

```shell
# pod状态为pending
/data/test_k3s # kubectl get po                                                                                   root@c71
NAME                                       READY   STATUS      RESTARTS        AGE
nfs-client-provisioner-97bc6b95-74ghx      0/1     Unknown     7               4d4h
wx-mp-nginx-deployment1-7898945b78-vz5xb   1/1     Running     2 (5m20s ago)   32h
wx-mp-nginx-deployment2-66658d4db5-klg8r   1/1     Running     2 (5m20s ago)   17h
cleanlog-27965539-lvlqh                    0/1     Completed   0               2m32s
cleanlog-27965540-lxgx9                    0/1     Completed   0               92s
cleanlog-27965541-gwvd4                    0/1     Completed   0               32s
wx-mp-nginx-deployment3-6696f4867b-spsh2   0/1     Pending     0               6s

# 通过describe查看相关报错
/data/test_k3s # kubectl describe po wx-mp-nginx-deployment3-6696f4867b-spsh2  
  Warning  FailedScheduling  54s   default-scheduler  0/1 nodes are available: 1 node(s) didn't have free ports for the requested pod ports. preemption: 0/1 nodes are available: 1 No preemption victims found for incoming pod.
  Warning  FailedScheduling  13s   default-scheduler  0/1 nodes are available: 1 node(s) didn't have free ports for the requested pod ports. preemption: 0/1 nodes are available: 1 No preemption victims found for incoming pod.
```

从报错信息来看，疑似是端口被占用，导致无法正常部署，查看nginx_deployment.yaml

```yaml
/data/test_k3s # cat deployment3_nginx.yml                                                                        root@c71
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wx-mp-nginx-deployment3
  labels:
    app: wx-mp-nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wx-mp-nginx
  template:
    metadata:
      labels:
        app: wx-mp-nginx
    spec:
      containers:
      - name: wx-mp-nginx
        image: nginx
        ports:
        - containerPort: 80
          # 使用了hostport做端口映射，端口为10012
          hostPort: 10012
        volumeMounts:
        - name: nginx-data
          mountPath: /usr/share/nginx/html/
      volumes:
        - name: nginx-data
          hostPath:
            path: /root/data/wx-mp-nginx3
            type: Directory

```

通过查看yaml文件，发现使用hostport做了一个端口映射，节点的10012端口映射到pod的80端口，去查看了监听的情况

```shell
# 监听情况，并没有10012的监听
/data/test_k3s # ss -ntlp |grep 10012      
# 访问本机的10012端口，有返回
/data/test_k3s # curl localhost:10012                                                                 
2
# 查看k3s的svc，发现没有nginx对应的svc，没有端口10012的nginx相关svc
/data/test_k3s # kubectl get svc -A                                                                  
NAMESPACE         NAME              TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                      AGE
default           kubernetes        ClusterIP      10.43.0.1       <none>          443/TCP                      11d
kube-system       kube-dns          ClusterIP      10.43.0.10      <none>          53/UDP,53/TCP,9153/TCP       11d
kube-system       metrics-server    ClusterIP      10.43.246.193   <none>          443/TCP                      11d
mongodb-cluster   mongo-cs          NodePort       10.43.176.123   <none>          27017:30717/TCP              4d2h
mongodb-cluster   mongodb-cluster   ClusterIP      None            <none>          27017/TCP                    4d
kube-system       traefik           LoadBalancer   10.43.152.32    192.168.216.3   80:31897/TCP,443:31954/TCP   11d
```

那疑问点就来了，节点没有10012的服务监听，且svc中没有相关的规则，那10012端口是什么程序以什么方式提供的呢？

看完了svc，突然想到上面的排查过程中忽略了iptables，尝试着看了下iptables中的10012端口信息

```shell
# 在iptables规则中发现了10012的相关信息
/data/test_k3s # iptables-save |grep 10012                                                          
-A CNI-DN-8b50ce5ffb7405f311251 -s 10.42.0.0/24 -p tcp -m tcp --dport 10012 -j CNI-HOSTPORT-SETMARK
-A CNI-DN-8b50ce5ffb7405f311251 -s 127.0.0.1/32 -p tcp -m tcp --dport 10012 -j CNI-HOSTPORT-SETMARK
-A CNI-DN-8b50ce5ffb7405f311251 -p tcp -m tcp --dport 10012 -j DNAT --to-destination 10.42.0.19:80
-A CNI-HOSTPORT-DNAT -p tcp -m comment --comment "dnat name: \"cbr0\" id: \"1a8ed5c180cf7028c9aba486888bfb097eea725349b0d4614d7445710f65ce16\"" -m multiport --dports 10012 -j CNI-DN-8b50ce5ffb7405f311251
```

上面几条规则将10.42.0网段及127.0.0.1的10012端口的访问转发到10.42.0.19的80端口

```shell
# 查看10.42.0.19在集群中的位置，发现是nginx-deployment2的pod
/data/test_k3s # kubectl get po -owide |grep 10.42.0.19                                                           root@c71
wx-mp-nginx-deployment2-66658d4db5-klg8r   1/1     Running     2 (22m ago)   17h     10.42.0.19   c71      <none>           <none>
# 查看对应的yaml，发现nginx-deployment2也配了hostPort，端口也是10012
/data/test_k3s # kubectl get po wx-mp-nginx-deployment2-66658d4db5-klg8r -oyaml  |grep -i hostport  
      hostPort: 10012

```

上网查了相关资料，hostport是以iptables的方式来实现从节点port路由到pod的端口，并且是以<hostIP,hostPort,Protocal>这个三元组来判断端口的占用，所以在nginx_deployment2已经占用了节点的10012端口后，ngxin_deployment发布时就提示端口占用了

## 建议

更改nginx_deployment中的hostPort端口，选择一个未被使用的端口

## 参考文档

[https://ranchermanager.docs.rancher.com/v2.0-v2.4/how-to-guides/new-user-guides/migrate-from-v1.6-v2.x/expose-services](https://ranchermanager.docs.rancher.com/v2.0-v2.4/how-to-guides/new-user-guides/migrate-from-v1.6-v2.x/expose-services)